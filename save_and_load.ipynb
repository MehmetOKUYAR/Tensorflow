{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBdde4YJeJKF"
   },
   "source": [
    "Model ilerlemesi eğitim sırasında ve sonrasında kaydedilebilir. Bu, bir modelin kaldığı yerden devam edebileceği ve uzun eğitim sürelerinden kaçınabileceği anlamına gelir. Kaydetmek, modelinizi paylaşabileceğiniz ve başkalarının da çalışmanızı yeniden oluşturabileceği anlamına gelir. Araştırma modellerini ve tekniklerini yayınlarken çoğu makine öğrenimi uygulayıcısı şunları paylaşır:\n",
    "\n",
    "* modeli oluşturmak için kod ve\n",
    "* model için eğitilmiş ağırlıklar veya parametreler\n",
    "\n",
    "Bu verileri paylaşmak, başkalarının modelin nasıl çalıştığını anlamalarına ve yeni verilerle kendi başlarına denemelerine yardımcı olur.\n",
    "\n",
    "Caution: Be careful with untrusted code—TensorFlow models are code. See [Using TensorFlow Securely](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for details.\n",
    "\n",
    "### Seçenekler\n",
    "Kullandığınız API'ye bağlı olarak TensorFlow modellerini kaydetmenin farklı yolları vardır. Bu kılavuz, TensorFlow'da modeller oluşturmak ve eğitmek için üst düzey bir API olan [tf.keras](https://www.tensorflow.org/guide/keras) kullanır. Diğer yaklaşımlar için, TensorFlow [Save and Restore](https://www.tensorflow.org/guide/saved_model) kılavuzuna veya  [Saving in eager](https://www.tensorflow.org/guide/eager#object-based_saving) konusuna bakın.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l0MiTOrXtNv"
   },
   "source": [
    "## Kurulum\n",
    "> ## Yüklemeler ve içe aktarmalar\n",
    "TensorFlow'u ve bağımlılıkları yükleyin ve içe aktarın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RzIOVSdnMYyO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Nm7Tyb-gRt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbGsznErXWt6"
   },
   "source": [
    "## Örnek bir veri kümesi alın \n",
    "Ağırlıkların nasıl kaydedilip yükleneceğini göstermek için [MNIST dataset](http://yann.lecun.com/exdb/mnist/) veri kümesini kullanacaksınız. Bu çalıştırmaları hızlandırmak için ilk 1000 örneği kullanın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9rGfFwE9XVwz"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bir model tanımlayın \n",
    "Basit bir sıralı model oluşturarak başlayın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0HZbJIjxyX1S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soDE0W_KH8rG"
   },
   "source": [
    "## Eğitim sırasında kontrol noktalarını kaydedin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRyd5qQQIXZm"
   },
   "source": [
    "Eğitimli bir modeli, onu yeniden eğitmek zorunda kalmadan kullanabilir veya eğitimi kaldığınız yerden alabilirsiniz - eğitim sürecinin kesintiye uğraması durumunda. `tf.keras.callbacks.ModelCheckpoint` geri `tf.keras.callbacks.ModelCheckpoint` , modelin hem eğitim sırasında hem de sonunda sürekli olarak kaydedilmesini sağlar.\n",
    "\n",
    "### Denetim noktası geri arama kullanımı\n",
    "Yalnızca eğitim sırasında ağırlık tasarrufu sağlayan bir `tf.keras.callbacks.ModelCheckpoint` geri `tf.keras.callbacks.ModelCheckpoint` oluşturun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IFPuhwntH8VH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 1.3154 - sparse_categorical_accuracy: 0.6178\n",
      "Epoch 00001: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 1.1940 - sparse_categorical_accuracy: 0.6560 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.7940\n",
      "Epoch 2/10\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.4228 - sparse_categorical_accuracy: 0.8867\n",
      "Epoch 00002: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4131 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.5309 - val_sparse_categorical_accuracy: 0.8370\n",
      "Epoch 3/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.2804 - sparse_categorical_accuracy: 0.9351\n",
      "Epoch 00003: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2764 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.4821 - val_sparse_categorical_accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.2260 - sparse_categorical_accuracy: 0.9399\n",
      "Epoch 00004: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2210 - sparse_categorical_accuracy: 0.9410 - val_loss: 0.4662 - val_sparse_categorical_accuracy: 0.8460\n",
      "Epoch 5/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.1421 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 00005: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1524 - sparse_categorical_accuracy: 0.9690 - val_loss: 0.4342 - val_sparse_categorical_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.1214 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 00006: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1221 - sparse_categorical_accuracy: 0.9770 - val_loss: 0.4100 - val_sparse_categorical_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.0911 - sparse_categorical_accuracy: 0.9825\n",
      "Epoch 00007: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.4140 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 8/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.0648 - sparse_categorical_accuracy: 0.9907\n",
      "Epoch 00008: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.4079 - val_sparse_categorical_accuracy: 0.8700\n",
      "Epoch 9/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.0542 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 00009: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.4100 - val_sparse_categorical_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.0364 - sparse_categorical_accuracy: 0.9973\n",
      "Epoch 00010: saving model to training_1\\cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.4151 - val_sparse_categorical_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230f3d68370>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "# Bu, optimize edicinin durumunu kaydetmeyle ilgili uyarılar oluşturabilir.\n",
    "#Bu uyarılar (ve bu dizüstü bilgisayardaki benzer uyarılar), \n",
    "#eski kullanımları caydırmak için mevcuttur ve göz ardı edilebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlM-sgyJO084"
   },
   "source": [
    "Bu, her dönemin sonunda güncellenen tek bir TensorFlow denetim noktası dosyası koleksiyonu oluşturur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gXG5FVKFOVQ3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 9899-B9E8\n",
      "\n",
      " Directory of C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\\training_2\n",
      "\n",
      "27.09.2020  20:07    <DIR>          .\n",
      "27.09.2020  20:07    <DIR>          ..\n",
      "27.09.2020  20:07                81 checkpoint\n",
      "27.09.2020  20:07         1.628.726 cp-0000.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07               402 cp-0000.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0005.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0005.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0010.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0010.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0015.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0015.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0020.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0020.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0025.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0025.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0030.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0030.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0035.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0035.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0040.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0040.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0045.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0045.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0050.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0050.ckpt.index\n",
      "              23 File(s)     50.508.279 bytes\n",
      "               2 Dir(s)  300.541.431.808 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlRN_f56Pqa9"
   },
   "source": [
    "Yeni, eğitimsiz bir model oluşturun. Bir modeli yalnızca ağırlıklardan geri yüklerken, orijinal modelle aynı mimariye sahip bir modeliniz olmalıdır. Aynı model mimarisi olduğundan, modelin farklı bir örneği olmasına rağmen ağırlıkları paylaşabilirsiniz.\n",
    "\n",
    "Şimdi yeni, eğitimsiz bir modeli yeniden oluşturun ve test setinde değerlendirin. Eğitimsiz bir model şans seviyelerinde performans gösterir (~% 10 doğruluk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Fp5gbuiaPqCT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "32/32 - 0s - loss: 2.3836 - sparse_categorical_accuracy: 0.0470\n",
      "Untrained model, accuracy:  4.70%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DTKpZssRSo3"
   },
   "source": [
    "Ardından ağırlıkları kontrol noktasından yükleyin ve yeniden değerlendirin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2IZxbwiRRSD2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4151 - sparse_categorical_accuracy: 0.8710\n",
      "Restored model, accuracy: 87.10%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpAbKkAyVPV8"
   },
   "source": [
    "### Denetim noktası geri arama seçenekleri\n",
    "Geri arama, denetim noktaları için benzersiz adlar sağlamak ve denetim noktası sıklığını ayarlamak için çeşitli seçenekler sunar.\n",
    "\n",
    "Yeni bir model eğitin ve her beş dönemde bir benzersiz olarak adlandırılmış kontrol noktalarını kaydedin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mQF_dlgIVOvq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Epoch 00005: saving model to training_2\\cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2\\cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2\\cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2\\cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2\\cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2\\cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2\\cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2\\cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2\\cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2\\cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230f4d5d2b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=5)\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=50, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zFrKTjjavWI"
   },
   "source": [
    "Şimdi, ortaya çıkan kontrol noktalarına bakın ve en yenisini seçin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p64q3-V4sXt0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 9899-B9E8\n",
      "\n",
      " Directory of C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\\training_2\n",
      "\n",
      "27.09.2020  20:07    <DIR>          .\n",
      "27.09.2020  20:07    <DIR>          ..\n",
      "27.09.2020  20:07                81 checkpoint\n",
      "27.09.2020  20:07         1.628.726 cp-0000.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07               402 cp-0000.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0005.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0005.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0010.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0010.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0015.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0015.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0020.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0020.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0025.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0025.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0030.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0030.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0035.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0035.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0040.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0040.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0045.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0045.ckpt.index\n",
      "27.09.2020  20:07         4.886.685 cp-0050.ckpt.data-00000-of-00001\n",
      "27.09.2020  20:07             1.222 cp-0050.ckpt.index\n",
      "              23 File(s)     50.508.279 bytes\n",
      "               2 Dir(s)  300.564.230.144 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1AN_fnuyR41H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk2ciGbKg561"
   },
   "source": [
    "* Not: Varsayılan tensorflow biçimi yalnızca en son 5 denetim noktasını kaydeder.\n",
    "\n",
    "Test etmek için modeli sıfırlayın ve en son kontrol noktasını yükleyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3M04jyK-H3QK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4882 - sparse_categorical_accuracy: 0.8760\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtdYhvWnH2ib"
   },
   "source": [
    "## Bu dosyalar nedir? \n",
    "Yukarıdaki kod, ağırlıkları yalnızca ikili formatta eğitilmiş ağırlıkları içeren [checkpoint](https://www.tensorflow.org/guide/saved_model#save_and_restore_variables) formatlı dosyalar koleksiyonunda depolar. Kontrol noktaları şunları içerir:\n",
    "\n",
    "* Modelinizin ağırlıklarını içeren bir veya daha fazla parça.\n",
    "* Hangi kırıkta hangi ağırlıkların saklandığını gösteren bir dizin dosyası.\n",
    "\n",
    "Bir modeli yalnızca tek bir makinede eğitiyorsanız, son `.data-00000-of-00001` sahip bir parçanız olur: `.data-00000-of-00001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_FA-ZvxuXQV"
   },
   "source": [
    "## Manually save weights\n",
    "\n",
    "You saw how to load the weights into a model. Manually saving them is just as simple with the `Model.save_weights` method. By default, `tf.keras`—and `save_weights` in particular—uses the TensorFlow [checkpoint](../../guide/checkpoint.ipynb) format with a `.ckpt` extension (saving in [HDF5](https://js.tensorflow.org/tutorials/import-keras.html) with a `.h5` extension is covered in the [Save and serialize models](../../guide/keras/save_and_serialize#weights-only_saving_in_savedmodel_format) guide):\n",
    "\n",
    "## Ağırlıkları manuel olarak kaydedin\n",
    "Ağırlıkları bir modele nasıl yükleyeceğinizi gördünüz. `Model.save_weights` yöntemiyle manuel olarak kaydetmek de aynı derecede basittir. Varsayılan, `tf.keras` -ve `save_weights` içinde TensorFlow özellikle-kullanır [checkpoint](../../guide/checkpoint.ipynb) bir ile biçimini `.ckpt` (kaydetme uzantılı[HDF5](https://js.tensorflow.org/tutorials/import-keras.html) bir ile .h5 kaplıdır uzantısı [Save and serialize models](../../guide/keras/save_and_serialize#weights-only_saving_in_savedmodel_format) modelleri rehber):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "R7W5plyZ-u9X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "32/32 - 0s - loss: 0.4882 - sparse_categorical_accuracy: 0.8760\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Evaluate the model\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOGlxPRBEvV1"
   },
   "source": [
    "## Save the entire model\n",
    "\n",
    "Call [`model.save`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save) to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, you can resume training from exactly where you left off.\n",
    "\n",
    "Entire model can be saved in two different file formats (`SavedModel` and `HDF5`). It is to be noted that TensorFlow `SavedModel` format is the default file format in TF2.x. However, model can be saved in `HDF5` format. More details on saving entire model in the two file formats is described below.\n",
    "\n",
    "Saving a fully-functional model is very useful—you can load them in TensorFlow.js ([Saved Model](https://www.tensorflow.org/js/tutorials/conversion/import_saved_model), [HDF5](https://www.tensorflow.org/js/tutorials/conversion/import_keras)) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite ([Saved Model](https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_), [HDF5](https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_))\n",
    "\n",
    "\\*Custom objects (e.g. subclassed models or layers) require special attention when saving and loading. See the **Saving custom objects** section below \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tüm modeli kaydedin\n",
    "Bir modelin mimarisini, ağırlıklarını ve eğitim yapılandırmasını tek bir dosyaya / klasöre kaydetmek için  [`model.save`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save) çağırın. Bu, bir modeli dışa aktarmanıza olanak tanır, böylece orijinal Python koduna * erişim olmadan kullanılabilir. Optimize edici durumu kurtarıldığından, eğitime tam olarak kaldığınız yerden devam edebilirsiniz.\n",
    "\n",
    "Tüm model iki farklı dosya biçiminde (`SavedModel` and `HDF5`) kaydedilebilir. TensorFlow `SavedModel` formatının `SavedModel` varsayılan dosya formatı olduğuna dikkat edilmelidir. Ancak model `HDF5` formatında kaydedilebilir. Modelin tamamını iki dosya biçiminde kaydetme hakkında daha fazla ayrıntı aşağıda açıklanmıştır.\n",
    "\n",
    "Tam işlevli bir modeli kaydetmek çok kullanışlıdır - bunları TensorFlow.js ([Saved Model](https://www.tensorflow.org/js/tutorials/conversion/import_saved_model) ,[HDF5](https://www.tensorflow.org/js/tutorials/conversion/import_keras) ) içine yükleyebilir ve ardından bunları web tarayıcılarında eğitip çalıştırabilir veya TensorFlow Lite ( [Saved Model](https://www.tensorflow.org/lite/convert/python_api#converting_a_savedmodel_) , [HDF5](https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_)) kullanarak mobil cihazlarda çalıştırmaya dönüştürebilirsiniz. )\n",
    "\n",
    "* Özel nesneler (örneğin, alt sınıflı modeller veya katmanlar) kaydederken ve yüklerken özel dikkat gerektirir. Aşağıdaki **Özel nesneleri kaydetme** bölümüne bakın"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPyhgcoVzqUB"
   },
   "source": [
    "### SavedModel format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtcN4VIb7JkK"
   },
   "source": [
    "The SavedModel format is another way to serialize models. Models saved in this format can be restored using `tf.keras.models.load_model` and are compatible with TensorFlow Serving. The [SavedModel guide](https://www.tensorflow.org/guide/saved_model) goes into detail about how to serve/inspect the SavedModel. The section below illustrates the steps to saving and restoring the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavedModel biçimi, modelleri serileştirmenin başka bir yoludur. Bu formatta kaydedilen modeller `tf.keras.models.load_model` kullanılarak geri yüklenebilir `tf.keras.models.load_model` ve TensorFlow Sunumu ile uyumludur. [SavedModel guide](https://www.tensorflow.org/guide/saved_model) , SavedModel'in nasıl sunulacağı / inceleneceği hakkında ayrıntılı bilgi verir. Aşağıdaki bölüm, modeli kaydetme ve geri yükleme adımlarını göstermektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sI1YvCDFzpl3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1981 - sparse_categorical_accuracy: 0.6540\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4235 - sparse_categorical_accuracy: 0.8920\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3006 - sparse_categorical_accuracy: 0.9260\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2048 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230fe3d4070>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUvT_3qE8hV5"
   },
   "source": [
    "The SavedModel format is a directory containing a protobuf binary and a Tensorflow checkpoint. Inspect the saved model directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavedModel biçimi, bir protobuf ikili dosyası ve bir Tensorflow denetim noktası içeren bir dizindir. Kaydedilen model dizinini inceleyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "sq8fPglI1RWA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 9899-B9E8\n",
      "\n",
      " Directory of C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\\saved_model\n",
      "\n",
      "27.09.2020  20:28    <DIR>          .\n",
      "27.09.2020  20:28    <DIR>          ..\n",
      "27.09.2020  20:28    <DIR>          my_model\n",
      "               0 File(s)              0 bytes\n",
      "               3 Dir(s)  300.539.244.544 bytes free\n"
     ]
    }
   ],
   "source": [
    "# my_model directory\n",
    "%ls saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] Sistem belirtilen yolu bulamıyor: 'saved_model/my_model'\n",
      "C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\\saved_model\\my_model\n"
     ]
    }
   ],
   "source": [
    "# Contains an assets folder, saved_model.pb, and variables folder.\n",
    "%cd saved_model/my_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 9899-B9E8\n",
      "\n",
      " Directory of C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\\saved_model\\my_model\n",
      "\n",
      "27.09.2020  20:28    <DIR>          .\n",
      "27.09.2020  20:28    <DIR>          ..\n",
      "27.09.2020  20:28    <DIR>          assets\n",
      "27.09.2020  20:28            78.738 saved_model.pb\n",
      "27.09.2020  20:28    <DIR>          variables\n",
      "               1 File(s)         78.738 bytes\n",
      "               4 Dir(s)  300.538.572.800 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%quickref #Python Hızlı Referans Kartını görüntüleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\\saved_model\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEHMET\\jupyter\\TENSORFLOW\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7qfpvpY9HCe"
   },
   "source": [
    "Kaydedilen modelden yeni bir Keras modelini yeniden yükleyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "0YofwHdN0pxa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWwgNaz19TH2"
   },
   "source": [
    "Geri yüklenen model, orijinal model ile aynı argümanlarla derlenir. Yüklenen modelle değerlendir ve tahmin et çalıştırmayı deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Yh5Mu0yOgE5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4378 - sparse_categorical_accuracy: 0.8570\n",
      "Restored model, accuracy: 85.70%\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkGwf-50zLNn"
   },
   "source": [
    "### HDF5 format\n",
    "\n",
    "Keras, HDF5 standardını kullanarak temel bir kaydetme formatı sağlar. [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) standard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "m2dkmJVCGUia"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1269 - sparse_categorical_accuracy: 0.6830\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4204 - sparse_categorical_accuracy: 0.8840\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2700 - sparse_categorical_accuracy: 0.9360\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2078 - sparse_categorical_accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWmttMOqS68S"
   },
   "source": [
    "Şimdi, modeli bu dosyadan yeniden oluşturun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "5NDMO_7kS6Do"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXQpbTicTBwt"
   },
   "source": [
    "Check its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "jwEaj9DnTCVA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4137 - sparse_categorical_accuracy: 0.8650\n",
      "Restored model, accuracy: 86.50%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGXqd4wWJl8O"
   },
   "source": [
    "Keras saves models by inspecting the architecture. This technique saves everything:\n",
    "\n",
    "* The weight values\n",
    "* The model's architecture\n",
    "* The model's training configuration(what you passed to compile)\n",
    "* The optimizer and its state, if any (this enables you to restart training where you left)\n",
    "\n",
    "Keras is not able to save the `v1.x` optimizers (from `tf.compat.v1.train`) since they aren't compatible with checkpoints. For v1.x optimizers, you need to re-compile the model after loading—losing the state of the optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras, mimariyi inceleyerek modelleri kaydeder. Bu teknik her şeyi kaydeder:\n",
    "\n",
    "* Ağırlık değerleri\n",
    "* Modelin mimarisi\n",
    "* Modelin eğitim yapılandırması (derlemek için geçtiğiniz şey)\n",
    "* Optimize edici ve varsa durumu (bu, eğitimi kaldığınız yerden yeniden başlatmanıza olanak tanır)\n",
    "\n",
    "`tf.compat.v1.train` , denetim noktaları ile uyumlu olmadıkları için `v1.x` optimize `v1.x`(`tf.compat.v1.train` ) tf.compat.v1.train . V1.x optimize ediciler için, optimize edicinin durumunu kaybederek yükledikten sonra modeli yeniden derlemeniz gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAUKJQyGqTNH"
   },
   "source": [
    "### Saving custom objects\n",
    "\n",
    "If you are using the SavedModel format, you can skip this section. The key difference between HDF5 and SavedModel is that HDF5 uses object configs to save the model architecture, while SavedModel saves the execution graph. Thus, SavedModels are able to save custom objects like subclassed models and custom layers without requiring the orginal code.\n",
    "\n",
    "To save custom objects to HDF5, you must do the following:\n",
    "\n",
    "1. Define a `get_config` method in your object, and optionally a `from_config` classmethod.\n",
    "  * `get_config(self)` returns a JSON-serializable dictionary of parameters needed to recreate the object.\n",
    "  * `from_config(cls, config)` uses the returned config from `get_config` to create a new object. By default, this function will use the config as initialization kwargs (`return cls(**config)`).\n",
    "2. Pass the object to the `custom_objects` argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. E.g. `tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})`\n",
    "\n",
    "See the [Writing layers and models from scratch](https://www.tensorflow.org/guide/keras/custom_layers_and_models) tutorial for examples of custom objects and `get_config`.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "save_and_load.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
